{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib.pyplot import imshow\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from model import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "batch_size = 16\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "# transform_train = transforms.Compose([transforms.Resize((image_size, image_size), interpolation=Image.ANTIALIAS), \\\n",
    "#                       transforms.RandomHorizontalFlip(),\n",
    "#                       transforms.ToTensor(), \n",
    "#                       normalize])\n",
    "transform_test = transforms.Compose([transforms.Resize((image_size, image_size), interpolation=Image.ANTIALIAS), \\\n",
    "                      transforms.ToTensor(), \n",
    "                      normalize])\n",
    "\n",
    "# data_train = datasets.ImageFolder('/scratch/rw2268/Handbag_brand/data/train', transform=transform_train)\n",
    "# train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
    "#                                                          shuffle=True, \n",
    "#                                                          num_workers=num_workers)\n",
    "\n",
    "# data_val = datasets.ImageFolder('/scratch/rw2268/Handbag_brand/data/val', transform=transform_test)\n",
    "# val_loader = torch.utils.data.DataLoader(data_val, batch_size=batch_size, \n",
    "#                                                      shuffle=False, \n",
    "#                                                      num_workers=num_workers)\n",
    "\n",
    "# data_test = datasets.ImageFolder('/scratch/rw2268/Handbag_brand/data/test', transform=transform_test)\n",
    "# test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, \n",
    "#                                                        shuffle=False, \n",
    "#                                                        num_workers=num_workers)\n",
    "\n",
    "\n",
    "data_test = datasets.ImageFolder(\"/Users/yuxiong/Desktop/Capstone/Fashion_Apparel_Detection/Capstone_Project/CNN-Classifier-Pytorch/data/test\", transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, \n",
    "                                                       shuffle=False, \n",
    "                                                       num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=['Louis_Vuitton',\n",
    " 'balenciaga',\n",
    " 'burberry',\n",
    " 'chloe',\n",
    " 'coach',\n",
    " 'givenchy',\n",
    " 'gucci',\n",
    " 'longchamp',\n",
    " 'michaelkors',\n",
    " 'prada',\n",
    " 'saint laurent',\n",
    " 'unknown',\n",
    " 'valentino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path= \"/Users/yuxiong/Desktop/Capstone/Fashion_Apparel_Detection/Capstone_Project/yolov3/0012.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(model):\n",
    "    try:\n",
    "    \n",
    "        model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    except:\n",
    "        return 0\n",
    "    print('Loaded trained model: {}!'.format(model_path))\n",
    "    #return int(os.path.basename(dir_).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters /USERS/YUXIONG/DESKTOP/CAPSTONE/FASHION_APPAREL_DETECTION/CAPSTONE_PROJECT/YOLOV3/0012.PTH - ImageNet (1000 outputs): 11689512\n",
      "The number of parameters /USERS/YUXIONG/DESKTOP/CAPSTONE/FASHION_APPAREL_DETECTION/CAPSTONE_PROJECT/YOLOV3/0012.PTH - Custom (13 outputs): 11696181\n"
     ]
    }
   ],
   "source": [
    "model = get_model(model_path, 13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 0.001, [0.5, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model: /Users/yuxiong/Desktop/Capstone/Fashion_Apparel_Detection/Capstone_Project/yolov3/0012.pth!\n"
     ]
    }
   ],
   "source": [
    "load_pretrained_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver(data_loader, model):\n",
    "    model.eval()\n",
    "   \n",
    "    count_test = 0\n",
    "    test_out = []\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(data_loader):\n",
    "        #data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        _, arg_max_out = torch.max(output.data.cpu(), 1)\n",
    "        \n",
    "        \n",
    "        for oo in arg_max_out:\n",
    "            test_out.append('%s,%d\\n'%(str(count_test).zfill(4), oo))\n",
    "            count_test+=1\n",
    "\n",
    "    #print(brand[int(test_out[0].split(\",\")[1])])\n",
    "\n",
    "    return brand[int(test_out[0].split(\",\")[1])]\n",
    "\n",
    "def test(test_loader, model):\n",
    "    #assert start_epoch>0, \"you must first TRAIN\"\n",
    "    #solver(config.model, val_loader, model,  mode='val')\n",
    "    return solver(test_loader, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gucci'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(train_loader.dataset.classes)\n",
    "num_classes\n",
    "train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_img = data_train.__getitem__(345)[0].numpy()\n",
    "# img = Image.fromarray(sp_img, 'RGB')\n",
    "sp_img = sp_img.transpose([1,2,0])\n",
    "imshow(sp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-trained CNN and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "num_epochs = 10\n",
    "num_epochs_decay = 60\n",
    "learning_rate = 0.001\n",
    "stop_training = 3\n",
    "def update_lr(lr, optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_layer(model, num_classes):\n",
    "    modules = model.modules()\n",
    "    for m in modules:\n",
    "        if isinstance(m, nn.Linear) and m.weight.data.size()[0]==1000:\n",
    "            w1 = m.weight.data[:num_classes]\n",
    "            b1 = m.bias.data[:num_classes]\n",
    "    try:\n",
    "        if type(model.classifier)==nn.Sequential:\n",
    "            mod = list(model.classifier) #Alexnet, VGG\n",
    "        else:\n",
    "            mod = [model.classifier] #DenseNet\n",
    "\n",
    "    except: \n",
    "        mod = [model.fc] #ResNet\n",
    "\n",
    "    weight = mod[-1].weight.size(1)\n",
    "    mod.pop()\n",
    "    mod.append(torch.nn.Linear(weight,num_classes))\n",
    "    new_classifier = torch.nn.Sequential(*mod)\n",
    "    model.classifier = new_classifier\n",
    "    modules = model.modules()\n",
    "    flag = False\n",
    "    for m in modules:\n",
    "        if isinstance(m, nn.Linear) and m.weight.data.size()[0]==num_classes:\n",
    "            m.weight.data = w1\n",
    "            m.bias.data = b1  \n",
    "            flag = True\n",
    "    assert flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "remove_layer(model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name, epoch):\n",
    "    dir_ = os.path.join('/scratch/rw2268/Handbag_brand/snapshot', name, '%s.pth'%(str(epoch).zfill(4)))\n",
    "    create_folder(os.path.dirname(dir_))\n",
    "    torch.save(model.state_dict(), dir_)\n",
    "    print('!!Saving model: {}!'.format(dir_))\n",
    "def create_folder(folder):\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solver(name, data_loader, model, epoch, optimizer=None, mode='train'):\n",
    "    model = model.to(device)\n",
    "    if optimizer is None: model.eval()\n",
    "    else: model.train()\n",
    "    loss_cum = []\n",
    "    Acc = 0\n",
    "    count_test = 0\n",
    "    test_out = []\n",
    "    Loss = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data,target) in tqdm(enumerate(data_loader), \n",
    "                total=len(data_loader), desc=\"!{} -> [{}] Epoch: {}\".format(name.upper(), mode.upper(),epoch)):\n",
    "        volatile = True if optimizer is None else False\n",
    "        data = Variable(data.to(device), volatile=volatile)\n",
    "        target = Variable(target.to(device), volatile=volatile)\n",
    "       \n",
    "        output = model(data)\n",
    "        loss = Loss(output,target)   \n",
    "        \n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "       \n",
    "\n",
    "        loss_cum.append(loss.data.cpu()[0])\n",
    "        _, arg_max_out = torch.max(output.data.cpu(), 1)\n",
    "      \n",
    "        if mode=='test':\n",
    "            for oo in arg_max_out:\n",
    "                test_out.append('%s,%d\\n'%(str(count_test).zfill(4), oo))\n",
    "                count_test+=1\n",
    "\n",
    "        Acc += arg_max_out.long().eq(target.data.cpu().long()).sum()\n",
    "#         if batch_idx % 20 == 0:\n",
    "#             print('Epoch:{}, batch:{}, Acc:{}'.format(epoch+1,batch_idx+1,Acc*100/)\n",
    "    ACC = float(Acc*100)/len(data_loader.dataset)\n",
    "    LOSS = np.array(loss_cum).mean()\n",
    "    if mode=='test':\n",
    "        f=open(os.path.join('snapshot', name, 'test.txt'),'w')\n",
    "        for line in test_out: f.writelines(line)\n",
    "        f.close()\n",
    "    else:\n",
    "        print(\"LOSS %s: %0.3f || ACC %s: %0.2f\"%(mode.upper(), LOSS, mode.upper(), ACC))\n",
    "    \n",
    "    return ACC\n",
    "\n",
    "#==========================================================================#\n",
    "def train(name,train_loader, val_loader, model, learning_rate=learning_rate):\n",
    "    val_before = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate, [0.5, 0.999])\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        solver(name, train_loader, model, epoch, optimizer=optimizer, mode='train')\n",
    "        val_acc = solver(name, val_loader, model, epoch, mode='val')\n",
    "        if val_acc>val_before:\n",
    "            save_model(model, name, epoch+1)\n",
    "            val_before=val_acc\n",
    "            flag_stop=0\n",
    "        else:\n",
    "            flag_stop+=1\n",
    "\n",
    "        if flag_stop==stop_training: \n",
    "            return\n",
    "\n",
    "    # Decay learning rate\n",
    "        if (epoch+1) > (num_epochs - num_epochs_decay):\n",
    "            learning_rate -= (learning_rate / float(num_epochs_decay))\n",
    "            update_lr(learning_rate, optimizer)\n",
    "            print ('Decay learning rate to: {}.'.format(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train('ResNet18',train_loader, val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
